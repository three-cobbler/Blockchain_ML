{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# fairing:include-cell\n",
    "import fire\n",
    "import joblib\n",
    "import logging\n",
    "import nbconvert\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import pprint\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "from importlib import reload\n",
    "from sklearn.datasets import make_regression\n",
    "from kubeflow.metadata import metadata\n",
    "from datetime import datetime\n",
    "import retrying\n",
    "import urllib3\n",
    "\n",
    "# Imports not to be included in the built docker image\n",
    "import util\n",
    "import kfp\n",
    "import kfp.components as comp\n",
    "import kfp.gcp as gcp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.compiler as compiler\n",
    "from kubernetes import client as k8s_client\n",
    "from kubeflow import fairing   \n",
    "from kubeflow.fairing.builders import append\n",
    "from kubeflow.fairing.deployers import job\n",
    "from kubeflow.fairing.preprocessors.converted_notebook import ConvertNotebookPreprocessorWithFire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named oauth2client.client",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-142829cafd0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_application_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named oauth2client.client"
     ]
    }
   ],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "credentials = GoogleCredentials.get_application_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pip installing requirements.txt\n",
      "pip installing KFP https://storage.googleapis.com/ml-pipeline/release/0.1.32/kfp.tar.gz\n",
      "pip installing fairing git+git://github.com/kubeflow/fairing.git@9b0d4ed4796ba349ac6067bbd802ff1d6454d015\n",
      "Configure docker credentials\n"
     ]
    }
   ],
   "source": [
    "# install required libs\n",
    "KFP_PACKAGE = 'https://storage.googleapis.com/ml-pipeline/release/0.1.32/kfp.tar.gz'\n",
    "FAIRING_PACKAGE = 'git+git://github.com/kubeflow/fairing.git'\n",
    "\n",
    "def init_install():\n",
    "  # Install the SDK\n",
    "  subprocess.check_call([\"pip3\", \"install\", \"--user\", \"-r\", \"requirements.txt\"])\n",
    "  subprocess.check_call([\"pip3\", \"install\", \"--user\", KFP_PACKAGE, \"--upgrade\"])\n",
    "  subprocess.check_call([\"pip3\", \"install\", \"--user\", FAIRING_PACKAGE])\n",
    "  subprocess.check_call([\"gcloud\", \"auth\", \"configure-docker\", \"--quiet\"])\n",
    "\n",
    "  if os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\"):\n",
    "    logging.info(\"Activating service account\")\n",
    "    subprocess.check_call([\"gcloud\", \"auth\", \"activate-service-account\",\n",
    "                           \"--key-file=\" +\n",
    "                           os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\"),\n",
    "                           \"--quiet\"])\n",
    "\n",
    "  # install python package\n",
    "  local_py_path = os.path.join(str(Path.home()), \".local/lib/python3.6/site-packages\")\n",
    "\n",
    "  if local_py_path not in sys.path:\n",
    "    logging.info(\"Add %s python_path\", local_py_path)\n",
    "    sys.path.insert(0, local_py_path)\n",
    "\n",
    "init_install()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model and predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_custom(test_size=0.3):\n",
    "\n",
    "    X, y = make_regression(n_samples=300, n_features=6, noise=0.15)\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=test_size,\n",
    "                                                        shuffle=False)\n",
    "\n",
    "    imputer = SimpleImputer()\n",
    "    train_X = imputer.fit_transform(train_X)\n",
    "    test_X = imputer.transform(test_X)\n",
    "\n",
    "    return (train_X, train_y), (test_X, test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the model and train the model with training data\n",
    "def train_model(train_X,\n",
    "                train_y,\n",
    "                test_X,\n",
    "                test_y,\n",
    "                n_estimators,\n",
    "                learning_rate):\n",
    "\n",
    "    # choose model     \n",
    "    model = XGBRegressor(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "    # fit data in to the model\n",
    "    model.fit(train_X,\n",
    "              train_y,\n",
    "              early_stopping_rounds=40,\n",
    "              eval_set=[(test_X, test_y)])\n",
    "\n",
    "    return model\n",
    "\n",
    "# evaluate the model perfomance\n",
    "def evaluate_model(model, test_X, test_y):\n",
    "    predictions = model.predict(test_X)\n",
    "\n",
    "    return mean_absolute_error(predictions, test_y)\n",
    "\n",
    "# save the model\n",
    "def save_model(model, model_file):\n",
    "    joblib.dump(model, model_file)\n",
    "\n",
    "# create kubeflow metadata workspace\n",
    "def create_workspace():\n",
    "    METADATA_STORE_HOST = \"metadata-grpc-service.kubeflow\" # default DNS of Kubeflow Metadata gRPC serivce.\n",
    "    METADATA_STORE_PORT = 8080\n",
    "    return metadata.Workspace(\n",
    "        store=metadata.Store(grpc_host=METADATA_STORE_HOST, grpc_port=METADATA_STORE_PORT),\n",
    "        name=\"xgboost-synthetic\",\n",
    "        description=\"workspace for xgboost-synthetic artifacts and executions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-a06c1a37544c>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-a06c1a37544c>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    self.exec = self.create_execution()\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# class created to use kubeflow fairing to launch separate training jobs and deploy model on kubernets\n",
    "class ModelServe(object):    \n",
    "    def __init__(self, model_file=None):\n",
    "        self.n_estimators = 50\n",
    "        self.learning_rate = 0.15\n",
    "\n",
    "        if not model_file:\n",
    "            if \"MODEL_FILE\" in os.environ:\n",
    "                print(\"use passed model file\")\n",
    "                model_file = os.getenv(\"MODEL_FILE\")\n",
    "            else:\n",
    "                print(\"use default MODEL_FILE\")\n",
    "                model_file = \"mockup-model.dat\"\n",
    "        \n",
    "        self.model_file = model_file\n",
    "        print(\"model_file={0}\".format(self.model_file))\n",
    "        \n",
    "        self.model = None\n",
    "        self._workspace = None\n",
    "        self.exec = self.init_execution()\n",
    "\n",
    "    def train(self):\n",
    "        (train_X, train_y), (test_X, test_y) = train_test_split_custom()\n",
    "        \n",
    "        # use kubeflow metadata library to record meta data\n",
    "        self.exec.log_input(metadata.DataSet(\n",
    "            description=\"xgboost synthetic data\",\n",
    "            name=\"synthetic-data\",\n",
    "            owner=\"someone@kubeflow.org\",\n",
    "            uri=\"file://path/to/dataset\",\n",
    "            version=\"v1.0.0\"))\n",
    "        \n",
    "        model = train_model(train_X,\n",
    "                            train_y,\n",
    "                            test_X,\n",
    "                            test_y,\n",
    "                            self.n_estimators,\n",
    "                            self.learning_rate)\n",
    "        \n",
    "        # log meta data\n",
    "        self.exec.log_output(metadata.Metrics(\n",
    "            name=\"xgboost-synthetic-traing-eval\",\n",
    "            owner=\"someone@kubeflow.org\",\n",
    "            description=\"training evaluation for xgboost synthetic\",\n",
    "            uri=\"gcs://path/to/metrics\",\n",
    "            metrics_type=metadata.Metrics.VALIDATION,\n",
    "            values={\"mean_absolute_error\": evaluate_model(model, test_X, test_y)}))\n",
    "        \n",
    "        # save model\n",
    "        save_model(model, self.model_file)\n",
    "        \n",
    "        # log output\n",
    "        self.exec.log_output(metadata.Model(\n",
    "            name=\"housing-price-model\",\n",
    "            description=\"housing price prediction model using synthetic data\",\n",
    "            owner=\"someone@kubeflow.org\",\n",
    "            uri=self.model_file,\n",
    "            model_type=\"linear_regression\",\n",
    "            training_framework={\n",
    "                \"name\": \"xgboost\",\n",
    "                \"version\": \"0.9.0\"\n",
    "            },\n",
    "            hyperparameters={\n",
    "                \"learning_rate\": self.learning_rate,\n",
    "                \"n_estimators\": self.n_estimators\n",
    "            },\n",
    "            version=datetime.utcnow().isoformat(\"T\")))\n",
    "        \n",
    "    def predict(self, X, feature_names):\n",
    "        \"\"\"Predict using the model for given ndarray.\n",
    "        \n",
    "        The predict signature should match the syntax expected by Seldon Core\n",
    "        https://github.com/SeldonIO/seldon-core so that we can use\n",
    "        Seldon h to wrap it a model server and deploy it on Kubernetes\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            self.model = joblib.load(self.model_file)\n",
    "        prediction = self.model.predict(data=X)\n",
    "\n",
    "        return [[prediction.item(0), prediction.item(1)]]\n",
    "\n",
    "    @property\n",
    "    def workspace(self):\n",
    "        if not self._workspace:\n",
    "            self._workspace = create_workspace()\n",
    "        return self._workspace\n",
    "    \n",
    "    def init_execution(self):                \n",
    "        r = metadata.Run(\n",
    "            workspace=self.workspace,\n",
    "            name=\"xgboost-synthetic-faring-run\" + datetime.utcnow().isoformat(\"T\"),\n",
    "            description=\"a notebook run\")\n",
    "\n",
    "        return metadata.Execution(\n",
    "            name = \"execution\" + datetime.utcnow().isoformat(\"T\"),\n",
    "            workspace=self.workspace,\n",
    "            run=r,\n",
    "            description=\"execution for training xgboost-synthetic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MetadataStore with gRPC connection initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_file=mockup-model.dat\n",
      "[23:44:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:134.005\n",
      "Will train until validation_0-rmse hasn't improved in 40 rounds.\n",
      "[1]\tvalidation_0-rmse:129.102\n",
      "[2]\tvalidation_0-rmse:124.39\n",
      "[3]\tvalidation_0-rmse:119.218\n",
      "[4]\tvalidation_0-rmse:114.096\n",
      "[5]\tvalidation_0-rmse:109.494\n",
      "[6]\tvalidation_0-rmse:107.101\n",
      "[7]\tvalidation_0-rmse:103.463\n",
      "[8]\tvalidation_0-rmse:100.657\n",
      "[9]\tvalidation_0-rmse:96.576\n",
      "[10]\tvalidation_0-rmse:94.8884\n",
      "[11]\tvalidation_0-rmse:91.7095\n",
      "[12]\tvalidation_0-rmse:90.7389\n",
      "[13]\tvalidation_0-rmse:88.1934\n",
      "[14]\tvalidation_0-rmse:86.1535\n",
      "[15]\tvalidation_0-rmse:84.8222\n",
      "[16]\tvalidation_0-rmse:83.5818\n",
      "[17]\tvalidation_0-rmse:81.6697\n",
      "[18]\tvalidation_0-rmse:80.2789\n",
      "[19]\tvalidation_0-rmse:79.4583\n",
      "[20]\tvalidation_0-rmse:78.4213\n",
      "[21]\tvalidation_0-rmse:77.0478\n",
      "[22]\tvalidation_0-rmse:75.3792\n",
      "[23]\tvalidation_0-rmse:73.9913\n",
      "[24]\tvalidation_0-rmse:73.2026\n",
      "[25]\tvalidation_0-rmse:72.2079\n",
      "[26]\tvalidation_0-rmse:70.9489\n",
      "[27]\tvalidation_0-rmse:70.5206\n",
      "[28]\tvalidation_0-rmse:69.8641\n",
      "[29]\tvalidation_0-rmse:69.0409\n",
      "[30]\tvalidation_0-rmse:68.3776\n",
      "[31]\tvalidation_0-rmse:67.2776\n",
      "[32]\tvalidation_0-rmse:66.7612\n",
      "[33]\tvalidation_0-rmse:65.9548\n",
      "[34]\tvalidation_0-rmse:65.5048\n",
      "[35]\tvalidation_0-rmse:64.8582\n",
      "[36]\tvalidation_0-rmse:64.118\n",
      "[37]\tvalidation_0-rmse:63.5615\n",
      "[38]\tvalidation_0-rmse:63.2716\n",
      "[39]\tvalidation_0-rmse:62.9765\n",
      "[40]\tvalidation_0-rmse:62.3468\n",
      "[41]\tvalidation_0-rmse:62.0579\n",
      "[42]\tvalidation_0-rmse:61.9598\n",
      "[43]\tvalidation_0-rmse:61.6452\n",
      "[44]\tvalidation_0-rmse:61.2468\n",
      "[45]\tvalidation_0-rmse:60.7332\n",
      "[46]\tvalidation_0-rmse:60.6493\n",
      "[47]\tvalidation_0-rmse:60.2032\n",
      "[48]\tvalidation_0-rmse:59.9972\n",
      "[49]\tvalidation_0-rmse:59.5956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean_absolute_error=47.22\n",
      "Model export success: mockup-model.dat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE on eval: %.2f with %d rounds 59.595573 50\n"
     ]
    }
   ],
   "source": [
    "# train model locally\n",
    "model = ModelServe(model_file=\"mockup-model.dat\")\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MetadataStore with gRPC connection initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_file not supplied; using the default\n",
      "model_file=mockup-model.dat\n",
      "[23:44:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[-30.6968994140625, 45.884098052978516]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict model \n",
    "(train_X, train_y), (test_X, test_y) = train_test_split_custom()\n",
    "\n",
    "ModelServe().predict(test_X, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and deploy model on Kubernetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up google container repositories (GCR) for storing output containers\n",
    "GCP_PROJECT = fairing.cloud.gcp.guess_project_name()\n",
    "DOCKER_REGISTRY = 'gcr.io/{}/fairing-job'.format(GCP_PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the docker image using Kubeflow fairing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow.fairing import constants\n",
    "constants.constants.KANIKO_IMAGE = \"gcr.io/kaniko-project/executor:v0.14.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting build-train-deploy.ipynb to build-train-deploy.py\n",
      "Creating entry point for the class name ModelServe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PosixPath('build-train-deploy.py'), 'xgboost_util.py', 'mockup-model.dat']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kubeflow.fairing.builders import cluster\n",
    "\n",
    "# output_map is a map of extra files to add to the notebook.\n",
    "output_map =  {\n",
    "    \"Dockerfile\": \"Dockerfile\",\n",
    "    \"requirements.txt\": \"requirements.txt\",\n",
    "}\n",
    "\n",
    "\n",
    "preprocessor = ConvertNotebookPreprocessorWithFire(class_name='ModelServe', \n",
    "                                                   notebook_file='build-train-deploy.ipynb',\n",
    "                                                   output_map=output_map)\n",
    "\n",
    "if not preprocessor.input_files:\n",
    "    preprocessor.input_files = set()\n",
    "input_files=[\"xgboost_util.py\", \"mockup-model.dat\"]\n",
    "preprocessor.input_files =  set([os.path.normpath(f) for f in input_files])\n",
    "preprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build base image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building image using cluster builder.\n",
      "Creating docker context: /tmp/fairing_context_n34sz0lr\n",
      "Converting build-train-deploy.ipynb to build-train-deploy.py\n",
      "Creating entry point for the class name ModelServe\n",
      "Not able to find gcp credentials secret: user-gcp-sa\n",
      "Trying workload identity service account: default-editor\n",
      "Waiting for fairing-builder-dcbz2-lqzjg to start...\n",
      "Waiting for fairing-builder-dcbz2-lqzjg to start...\n",
      "Waiting for fairing-builder-dcbz2-lqzjg to start...\n",
      "Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: logging before flag.Parse: E0226 23:44:52.505936       1 metadata.go:241] Failed to unmarshal scopes: invalid character 'h' looking for beginning of value\n",
      "\u001b[36mINFO\u001b[0m[0002] Resolved base name gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0 to gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0\n",
      "\u001b[36mINFO\u001b[0m[0002] Resolved base name gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0 to gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0\n",
      "\u001b[36mINFO\u001b[0m[0002] Downloading base image gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0\n",
      "\u001b[36mINFO\u001b[0m[0002] Error while retrieving image from cache: getting file info: stat /cache/sha256:fe174faf7c477bc3dae796b067d98ac3f0d31e8075007a1146f86d13f2c98e13: no such file or directory\n",
      "\u001b[36mINFO\u001b[0m[0002] Downloading base image gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0\n",
      "\u001b[36mINFO\u001b[0m[0003] Built cross stage deps: map[]\n",
      "\u001b[36mINFO\u001b[0m[0003] Downloading base image gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0\n",
      "\u001b[36mINFO\u001b[0m[0003] Error while retrieving image from cache: getting file info: stat /cache/sha256:fe174faf7c477bc3dae796b067d98ac3f0d31e8075007a1146f86d13f2c98e13: no such file or directory\n",
      "\u001b[36mINFO\u001b[0m[0003] Downloading base image gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0\n",
      "\u001b[36mINFO\u001b[0m[0003] Using files from context: [/kaniko/buildcontext/requirements.txt]\n",
      "\u001b[36mINFO\u001b[0m[0003] Checking for cached layer gcr.io/kubeflow-ci/fairing-job/fairing-job/cache:233bc2f24de09b29aa4c12d0f5adcc3098286c3c35eb0b4864fa00f73d8b9d2c...\n",
      "\u001b[36mINFO\u001b[0m[0003] Using caching version of cmd: COPY requirements.txt .\n",
      "\u001b[36mINFO\u001b[0m[0003] cmd: USER\n",
      "\u001b[36mINFO\u001b[0m[0003] Checking for cached layer gcr.io/kubeflow-ci/fairing-job/fairing-job/cache:1acac4c9cb73d1b18003ae6076fd264e37af3983927234122784b04452b9b44e...\n",
      "\u001b[36mINFO\u001b[0m[0004] Using caching version of cmd: RUN pip3 --no-cache-dir install -r requirements.txt\n",
      "\u001b[36mINFO\u001b[0m[0004] cmd: USER\n",
      "\u001b[36mINFO\u001b[0m[0004] Skipping unpacking as no commands require it.\n",
      "\u001b[36mINFO\u001b[0m[0004] Taking snapshot of full filesystem...\n",
      "\u001b[36mINFO\u001b[0m[0004] COPY requirements.txt .\n",
      "\u001b[36mINFO\u001b[0m[0004] Found cached layer, extracting to filesystem\n",
      "\u001b[36mINFO\u001b[0m[0004] extractedFiles: [/tf/requirements.txt / /tf]\n",
      "\u001b[36mINFO\u001b[0m[0004] Taking snapshot of files...\n",
      "\u001b[36mINFO\u001b[0m[0004] USER root\n",
      "\u001b[36mINFO\u001b[0m[0004] cmd: USER\n",
      "\u001b[36mINFO\u001b[0m[0004] No files changed in this command, skipping snapshotting.\n",
      "\u001b[36mINFO\u001b[0m[0004] RUN pip3 --no-cache-dir install -r requirements.txt\n",
      "\u001b[36mINFO\u001b[0m[0004] Found cached layer, extracting to filesystem\n",
      "\u001b[36mINFO\u001b[0m[0032] Taking snapshot of files...\n",
      "\u001b[36mINFO\u001b[0m[0070] USER jovyan\n",
      "\u001b[36mINFO\u001b[0m[0070] cmd: USER\n",
      "\u001b[36mINFO\u001b[0m[0070] No files changed in this command, skipping snapshotting.\n"
     ]
    }
   ],
   "source": [
    "base_image = \"gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0\"\n",
    "cluster_builder = cluster.cluster.ClusterBuilder(registry=DOCKER_REGISTRY,\n",
    "                                                 base_image=base_image,\n",
    "                                                 preprocessor=preprocessor,\n",
    "                                                 dockerfile_path=\"Dockerfile\",\n",
    "                                                 pod_spec_mutators=[fairing.cloud.gcp.add_gcp_credentials_if_exists],\n",
    "                                                 context_source=cluster.gcs_context.GCSContextSource())\n",
    "cluster_builder.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the actual image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting build-train-deploy.ipynb to build-train-deploy.py\n",
      "Creating entry point for the class name ModelServe\n",
      "Building image using Append builder...\n",
      "Creating docker context: /tmp/fairing_context_x4g0orab\n",
      "Converting build-train-deploy.ipynb to build-train-deploy.py\n",
      "Creating entry point for the class name ModelServe\n",
      "build-train-deploy.py already exists in Fairing context, skipping...\n",
      "Loading Docker credentials for repository 'gcr.io/kubeflow-ci/fairing-job/fairing-job:F47EE88D'\n",
      "Invoking 'docker-credential-gcloud' to obtain Docker credentials.\n",
      "Successfully obtained Docker credentials.\n",
      "Image successfully built in 2.249176573008299s.\n",
      "Pushing image gcr.io/kubeflow-ci/fairing-job/fairing-job:BDE79D77...\n",
      "Loading Docker credentials for repository 'gcr.io/kubeflow-ci/fairing-job/fairing-job:BDE79D77'\n",
      "Invoking 'docker-credential-gcloud' to obtain Docker credentials.\n",
      "Successfully obtained Docker credentials.\n",
      "Uploading gcr.io/kubeflow-ci/fairing-job/fairing-job:BDE79D77\n",
      "Layer sha256:8832e37735788665026956430021c6d1919980288c66c4526502965aeb5ac006 exists, skipping\n",
      "Layer sha256:b4ecb6928817c974946ba93ffc5ce60de886457eb57955dae9d7bc8facfb690a exists, skipping\n",
      "Layer sha256:9269cef1ab8b202433fe1dfbfbdf4649926d70d7a8b94f0324421bda79b917fa exists, skipping\n",
      "Layer sha256:d77b634303a107b22366d05d1071bf79e7d2a27b3d6db1fb726fcfd5dd5f9831 exists, skipping\n",
      "Layer sha256:5bd1cb59702536c10e96bb14e54846922c9b257580d4e2c733076a922525240b exists, skipping\n",
      "Layer sha256:7babe47a4c402afbe26f10dffceb85be7bfd2072a96b816814503f41ce9c5273 exists, skipping\n",
      "Layer sha256:21a7832aeb8625dc8228ceb115a28222f87e0fbce61b2588c42a2cce7a3a63d6 exists, skipping\n",
      "Layer sha256:107cba84ef3d72ed995c76c7a4f60ba5613f58b029ab7e42ac20ece99bec88b1 exists, skipping\n",
      "Layer sha256:a31c3b1caad473a474d574283741f880e37c708cc06ee620d3e93fa602125ee0 exists, skipping\n",
      "Layer sha256:92d24c89f5bc70958385728755b042a5a45bddf2f997de80e84d1161f43ba316 exists, skipping\n",
      "Layer sha256:e590ee7edf442435692956d6fed54190416a217147a50c63e73a6a78d15bec84 exists, skipping\n",
      "Layer sha256:96685dce34a0d24bf69741972441398cffbed89aed4f40e3c063176c59a3c81c exists, skipping\n",
      "Layer sha256:daa5c419d33d51d1730ea530f4f7335640f5bb42856f319c63a1a521aee368c1 exists, skipping\n",
      "Layer sha256:016724bbd2c9643f24eff7c1e86d9202d7c04caddd7fdd4375a77e3998ce8203 exists, skipping\n",
      "Layer sha256:b5494e32d0131350be270a54399cee65934e90d3c2df87a83757903e627813b2 exists, skipping\n",
      "Layer sha256:823f4685c03b26a545ca41dcdca1e782ad5e52cf85bac03113edaa6aebdca1b3 exists, skipping\n",
      "Layer sha256:777cec03b3e23c21f8cf78f07812cc83dd7f352719226f27f361c5b706f6a93f exists, skipping\n",
      "Layer sha256:dc2840b4417186d66a29d64a039ac164be95929211d808294d36acae9301fc6b exists, skipping\n",
      "Layer sha256:5e671b828b2af02924968841e5d12084fa78e8722e9510402aaee80dc5d7a6db exists, skipping\n",
      "Layer sha256:5bac0c144f6e0b7082e3691da95d3f057ee0be0735e9efca76096da59cfd1786 exists, skipping\n",
      "Layer sha256:5b7339215d1d5f8e68622d584a224f60339f5bef41dbd74330d081e912f0cddd exists, skipping\n",
      "Layer sha256:35daced67e5901b8de4a92bca9fdc67c8593d400aae483591987442f54c87d0a exists, skipping\n",
      "Layer sha256:330a9002e0b4aa1e27d3628dd3f02ff9a39d25745b8f2f219b06e3725153ffc0 exists, skipping\n",
      "Layer sha256:4e8a6b90828e0d339f646d723df8720ffa17c0ffb905f8f009faf1be320ab5d9 exists, skipping\n",
      "Layer sha256:2b940936f9933b7737cf407f2149dd7393998d7a0bee5acf1c4a57b0487cef79 exists, skipping\n",
      "Layer sha256:d684674aa1a4d080be26286fd9356f573b80d2448599392e3dcf3c61ce98a0f0 exists, skipping\n",
      "Layer sha256:68543864d6442a851eaff0500161b92e4a151051cf7ed2649b3790a3f876bada exists, skipping\n",
      "Layer sha256:21640f54008ccbfc0d100246633f8e6f18f918a0566561f61aebbda785321e56 exists, skipping\n",
      "Layer sha256:f44c204b040238da05a21af1fd8543ea95f1e9249fac34b3b65217e38815568d exists, skipping\n",
      "Layer sha256:b054a26005b7f3b032577f811421fab5ec3b42ce45a4012dfa00cf6ed6191b0f exists, skipping\n",
      "Layer sha256:14ca88e9f6723ce82bc14b241cda8634f6d19677184691d086662641ab96fe68 exists, skipping\n",
      "Layer sha256:e3ab47ad84d9e11c5fad45791ce00ec5b5f3b7f1ae61a5fab17eb44c399d910f exists, skipping\n",
      "Layer sha256:01ad04a655b291ed8502f23f5b8c73d94475763e9b3cdbf6d1107f7879aadac6 exists, skipping\n",
      "Layer sha256:4b9d9f2fa2a2b168f0a49fcd3074c885ab1ca2c507848f7b2e3cee8104f1f7c3 exists, skipping\n",
      "Layer sha256:5bd2e6f0de430cd3936eec59afb6cf466b052344fe4348ac33a48ac903b661e2 exists, skipping\n",
      "Layer sha256:15bca5bd6fdc1b1ac156de08ce3b0f57760b345556b64017d1be5cc7c95e5e5b pushed.\n",
      "Layer sha256:d23f2bdcc84f066126b083288f75d140d58fc252618bda5bf05cb9696a183958 pushed.\n",
      "Finished upload of: gcr.io/kubeflow-ci/fairing-job/fairing-job:BDE79D77\n",
      "Pushed image gcr.io/kubeflow-ci/fairing-job/fairing-job:BDE79D77 in 2.74867532402277s.\n"
     ]
    }
   ],
   "source": [
    "preprocessor.preprocess()\n",
    "\n",
    "builder = append.append.AppendBuilder(registry=DOCKER_REGISTRY,\n",
    "                                      base_image=cluster_builder.image_tag, \n",
    "                                      preprocessor=preprocessor)\n",
    "builder.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use kubeflow fairing to launch Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Not able to find gcp credentials secret: user-gcp-sa\n",
      "Trying workload identity service account: default-editor\n",
      "The job fairing-job-qwdlb launched.\n",
      "Waiting for fairing-job-qwdlb-67ddb to start...\n",
      "Waiting for fairing-job-qwdlb-67ddb to start...\n",
      "Waiting for fairing-job-qwdlb-67ddb to start...\n",
      "Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-26 23:48:04.056153: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-02-26 23:48:04.056318: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-02-26 23:48:04.056332: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0226 23:48:06.277673 140238089848640 metadata_store.py:80] MetadataStore with gRPC connection initialized\n",
      "model_file not supplied; using the default\n",
      "model_file=mockup-model.dat\n",
      "[23:48:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:106.201\n",
      "Will train until validation_0-rmse hasn't improved in 40 rounds.\n",
      "[1]\tvalidation_0-rmse:102.289\n",
      "[2]\tvalidation_0-rmse:99.0904\n",
      "[3]\tvalidation_0-rmse:95.5223\n",
      "[4]\tvalidation_0-rmse:92.2357\n",
      "[5]\tvalidation_0-rmse:90.1649\n",
      "[6]\tvalidation_0-rmse:87.6004\n",
      "[7]\tvalidation_0-rmse:85.4127\n",
      "[8]\tvalidation_0-rmse:82.7163\n",
      "[9]\tvalidation_0-rmse:81.1641\n",
      "[10]\tvalidation_0-rmse:79.1006\n",
      "[11]\tvalidation_0-rmse:77.2564\n",
      "[12]\tvalidation_0-rmse:75.3755\n",
      "[13]\tvalidation_0-rmse:74.3393\n",
      "[14]\tvalidation_0-rmse:72.0505\n",
      "[15]\tvalidation_0-rmse:70.8315\n",
      "[16]\tvalidation_0-rmse:69.1124\n",
      "[17]\tvalidation_0-rmse:67.9681\n",
      "[18]\tvalidation_0-rmse:66.2094\n",
      "[19]\tvalidation_0-rmse:64.6999\n",
      "[20]\tvalidation_0-rmse:63.6925\n",
      "[21]\tvalidation_0-rmse:62.261\n",
      "[22]\tvalidation_0-rmse:60.887\n",
      "[23]\tvalidation_0-rmse:59.5543\n",
      "[24]\tvalidation_0-rmse:58.3673\n",
      "[25]\tvalidation_0-rmse:57.0439\n",
      "[26]\tvalidation_0-rmse:55.7172\n",
      "[27]\tvalidation_0-rmse:54.7011\n",
      "[28]\tvalidation_0-rmse:53.8976\n",
      "[29]\tvalidation_0-rmse:53.3325\n",
      "[30]\tvalidation_0-rmse:52.81\n",
      "[31]\tvalidation_0-rmse:51.8806\n",
      "[32]\tvalidation_0-rmse:50.9026\n",
      "[33]\tvalidation_0-rmse:50.0451\n",
      "[34]\tvalidation_0-rmse:49.2711\n",
      "[35]\tvalidation_0-rmse:48.6533\n",
      "[36]\tvalidation_0-rmse:47.8613\n",
      "[37]\tvalidation_0-rmse:47.5519\n",
      "[38]\tvalidation_0-rmse:46.9383\n",
      "[39]\tvalidation_0-rmse:46.7275\n",
      "[40]\tvalidation_0-rmse:46.1317\n",
      "[41]\tvalidation_0-rmse:45.7704\n",
      "[42]\tvalidation_0-rmse:45.4888\n",
      "[43]\tvalidation_0-rmse:44.8847\n",
      "[44]\tvalidation_0-rmse:44.5583\n",
      "[45]\tvalidation_0-rmse:43.9202\n",
      "[46]\tvalidation_0-rmse:43.7332\n",
      "[47]\tvalidation_0-rmse:43.2122\n",
      "[48]\tvalidation_0-rmse:43.0383\n",
      "[49]\tvalidation_0-rmse:42.7427\n",
      "I0226 23:48:06.457567 140238089848640 build-train-deploy.py:100] mean_absolute_error=33.15\n",
      "I0226 23:48:06.494030 140238089848640 build-train-deploy.py:106] Model export success: mockup-model.dat\n",
      "Best RMSE on eval: %.2f with %d rounds 42.742691 50\n"
     ]
    }
   ],
   "source": [
    "pod_spec = builder.generate_pod_spec()\n",
    "train_deployer = job.job.Job(cleanup=False,\n",
    "                             pod_spec_mutators=[\n",
    "                                 fairing.cloud.gcp.add_gcp_credentials_if_exists])\n",
    "\n",
    "pod_spec.containers[0].command.extend([\"train\"])\n",
    "result = train_deployer.deploy(pod_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: v1\n",
      "items:\n",
      "- apiVersion: batch/v1\n",
      "  kind: Job\n",
      "  metadata:\n",
      "    creationTimestamp: \"2020-02-26T23:47:21Z\"\n",
      "    generateName: fairing-job-\n",
      "    labels:\n",
      "      fairing-deployer: job\n",
      "      fairing-id: 54d568cc-58f2-11ea-964d-46fd3ccc57c5\n",
      "    name: fairing-job-qwdlb\n",
      "    namespace: zhenghui\n",
      "    resourceVersion: \"11375571\"\n",
      "    selfLink: /apis/batch/v1/namespaces/zhenghui/jobs/fairing-job-qwdlb\n",
      "    uid: 54d8d81b-58f2-11ea-a99d-42010a8000ac\n",
      "  spec:\n",
      "    backoffLimit: 0\n",
      "    completions: 1\n",
      "    parallelism: 1\n",
      "    selector:\n",
      "      matchLabels:\n",
      "        controller-uid: 54d8d81b-58f2-11ea-a99d-42010a8000ac\n",
      "    template:\n",
      "      metadata:\n",
      "        annotations:\n",
      "          sidecar.istio.io/inject: \"false\"\n",
      "        creationTimestamp: null\n",
      "        labels:\n",
      "          controller-uid: 54d8d81b-58f2-11ea-a99d-42010a8000ac\n",
      "          fairing-deployer: job\n",
      "          fairing-id: 54d568cc-58f2-11ea-964d-46fd3ccc57c5\n",
      "          job-name: fairing-job-qwdlb\n",
      "        name: fairing-deployer\n",
      "      spec:\n",
      "        containers:\n",
      "        - command:\n",
      "          - python\n",
      "          - /app/build-train-deploy.py\n",
      "          - train\n",
      "          env:\n",
      "          - name: FAIRING_RUNTIME\n",
      "            value: \"1\"\n",
      "          image: gcr.io/kubeflow-ci/fairing-job/fairing-job:BDE79D77\n",
      "          imagePullPolicy: IfNotPresent\n",
      "          name: fairing-job\n",
      "          resources: {}\n",
      "          securityContext:\n",
      "            runAsUser: 0\n",
      "          terminationMessagePath: /dev/termination-log\n",
      "          terminationMessagePolicy: File\n",
      "          workingDir: /app/\n",
      "        dnsPolicy: ClusterFirst\n",
      "        restartPolicy: Never\n",
      "        schedulerName: default-scheduler\n",
      "        securityContext: {}\n",
      "        serviceAccount: default-editor\n",
      "        serviceAccountName: default-editor\n",
      "        terminationGracePeriodSeconds: 30\n",
      "  status:\n",
      "    completionTime: \"2020-02-26T23:48:08Z\"\n",
      "    conditions:\n",
      "    - lastProbeTime: \"2020-02-26T23:48:08Z\"\n",
      "      lastTransitionTime: \"2020-02-26T23:48:08Z\"\n",
      "      status: \"True\"\n",
      "      type: Complete\n",
      "    startTime: \"2020-02-26T23:47:21Z\"\n",
      "    succeeded: 1\n",
      "kind: List\n",
      "metadata:\n",
      "  resourceVersion: \"\"\n",
      "  selfLink: \"\"\n"
     ]
    }
   ],
   "source": [
    "!kubectl get jobs -l fairing-id={train_deployer.job_id} -o yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the trained model to Kubeflow for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster endpoint: http://fairing-service-kkbtm.zhenghui.svc.cluster.local:5000/predict\n"
     ]
    }
   ],
   "source": [
    "from kubeflow.fairing.deployers import serving\n",
    "pod_spec = builder.generate_pod_spec()\n",
    "\n",
    "module_name = os.path.splitext(preprocessor.executable.name)[0]\n",
    "deployer = serving.serving.Serving(module_name + \".ModelServe\",\n",
    "                                   service_type=\"ClusterIP\",\n",
    "                                   labels={\"app\": \"mockup\"})\n",
    "    \n",
    "url = deployer.deploy(pod_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: extensions/v1beta1\r\n",
      "kind: Deployment\r\n",
      "metadata:\r\n",
      "  annotations:\r\n",
      "    deployment.kubernetes.io/revision: \"1\"\r\n",
      "  creationTimestamp: \"2020-02-26T23:48:12Z\"\r\n",
      "  generateName: fairing-deployer-\r\n",
      "  generation: 1\r\n",
      "  labels:\r\n",
      "    app: mockup\r\n",
      "    fairing-deployer: serving\r\n",
      "    fairing-id: 73532514-58f2-11ea-964d-46fd3ccc57c5\r\n",
      "  name: fairing-deployer-p8xc9\r\n",
      "  namespace: zhenghui\r\n",
      "  resourceVersion: \"11375642\"\r\n",
      "  selfLink: /apis/extensions/v1beta1/namespaces/zhenghui/deployments/fairing-deployer-p8xc9\r\n",
      "  uid: 7354b5ec-58f2-11ea-a99d-42010a8000ac\r\n",
      "spec:\r\n",
      "  progressDeadlineSeconds: 600\r\n",
      "  replicas: 1\r\n",
      "  revisionHistoryLimit: 10\r\n",
      "  selector:\r\n",
      "    matchLabels:\r\n",
      "      app: mockup\r\n",
      "      fairing-deployer: serving\r\n",
      "      fairing-id: 73532514-58f2-11ea-964d-46fd3ccc57c5\r\n",
      "  strategy:\r\n",
      "    rollingUpdate:\r\n",
      "      maxSurge: 25%\r\n",
      "      maxUnavailable: 25%\r\n",
      "    type: RollingUpdate\r\n",
      "  template:\r\n",
      "    metadata:\r\n",
      "      annotations:\r\n",
      "        sidecar.istio.io/inject: \"false\"\r\n",
      "      creationTimestamp: null\r\n",
      "      labels:\r\n",
      "        app: mockup\r\n",
      "        fairing-deployer: serving\r\n",
      "        fairing-id: 73532514-58f2-11ea-964d-46fd3ccc57c5\r\n",
      "      name: fairing-deployer\r\n",
      "    spec:\r\n",
      "      containers:\r\n",
      "      - command:\r\n",
      "        - seldon-core-microservice\r\n",
      "        - build-train-deploy.ModelServe\r\n",
      "        - REST\r\n",
      "        - --service-type=MODEL\r\n",
      "        - --persistence=0\r\n",
      "        env:\r\n",
      "        - name: FAIRING_RUNTIME\r\n",
      "          value: \"1\"\r\n",
      "        image: gcr.io/kubeflow-ci/fairing-job/fairing-job:BDE79D77\r\n",
      "        imagePullPolicy: IfNotPresent\r\n",
      "        name: model\r\n",
      "        resources: {}\r\n",
      "        securityContext:\r\n",
      "          runAsUser: 0\r\n",
      "        terminationMessagePath: /dev/termination-log\r\n",
      "        terminationMessagePolicy: File\r\n",
      "        workingDir: /app/\r\n",
      "      dnsPolicy: ClusterFirst\r\n",
      "      restartPolicy: Always\r\n",
      "      schedulerName: default-scheduler\r\n",
      "      securityContext: {}\r\n",
      "      terminationGracePeriodSeconds: 30\r\n",
      "status:\r\n",
      "  conditions:\r\n",
      "  - lastTransitionTime: \"2020-02-26T23:48:12Z\"\r\n",
      "    lastUpdateTime: \"2020-02-26T23:48:12Z\"\r\n",
      "    message: Deployment does not have minimum availability.\r\n",
      "    reason: MinimumReplicasUnavailable\r\n",
      "    status: \"False\"\r\n",
      "    type: Available\r\n",
      "  - lastTransitionTime: \"2020-02-26T23:48:12Z\"\r\n",
      "    lastUpdateTime: \"2020-02-26T23:48:13Z\"\r\n",
      "    message: ReplicaSet \"fairing-deployer-p8xc9-854c699677\" is progressing.\r\n",
      "    reason: ReplicaSetUpdated\r\n",
      "    status: \"True\"\r\n",
      "    type: Progressing\r\n",
      "  observedGeneration: 1\r\n",
      "  replicas: 1\r\n",
      "  unavailableReplicas: 1\r\n",
      "  updatedReplicas: 1\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get deploy -o yaml {deployer.deployment.metadata.name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send an inference request to the prediction server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = train_test_split_custom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'{\"data\":{\"names\":[\"t:0\",\"t:1\"],\"tensor\":{\"shape\":[1,2],\"values\":[-49.2782592'\n",
      " b'7734375,-54.25324630737305]}},\"meta\":{}}\\n')\n"
     ]
    }
   ],
   "source": [
    "result = util.predict_nparray(url, test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track Models and Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MetadataStore with gRPC connection initialized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 3,\n",
       "  'workspace': 'xgboost-synthetic',\n",
       "  'run': 'xgboost-synthetic-faring-run2020-02-26T23:26:36.443396',\n",
       "  'version': '2020-02-26T23:26:36.660862',\n",
       "  'owner': 'someone@kubeflow.org',\n",
       "  'description': 'housing price prediction model using synthetic data',\n",
       "  'name': 'housing-price-model',\n",
       "  'model_type': 'linear_regression',\n",
       "  'create_time': '2020-02-26T23:26:36.660887Z',\n",
       "  'uri': 'mockup-model.dat',\n",
       "  'training_framework': {'name': 'xgboost', 'version': '0.9.0'},\n",
       "  'hyperparameters': {'learning_rate': 0.1, 'n_estimators': 50},\n",
       "  'labels': None,\n",
       "  'kwargs': {}},\n",
       " {'id': 6,\n",
       "  'workspace': 'xgboost-synthetic',\n",
       "  'run': 'xgboost-synthetic-faring-run2020-02-26T23:27:11.144500',\n",
       "  'create_time': '2020-02-26T23:27:11.458520Z',\n",
       "  'version': '2020-02-26T23:27:11.458480',\n",
       "  'owner': 'someone@kubeflow.org',\n",
       "  'description': 'housing price prediction model using synthetic data',\n",
       "  'name': 'housing-price-model',\n",
       "  'model_type': 'linear_regression',\n",
       "  'uri': 'mockup-model.dat',\n",
       "  'training_framework': {'name': 'xgboost', 'version': '0.9.0'},\n",
       "  'hyperparameters': {'learning_rate': 0.1, 'n_estimators': 50},\n",
       "  'labels': None,\n",
       "  'kwargs': {}},\n",
       " {'id': 9,\n",
       "  'workspace': 'xgboost-synthetic',\n",
       "  'run': 'xgboost-synthetic-faring-run2020-02-26T23:30:04.636580',\n",
       "  'create_time': '2020-02-26T23:30:04.866997Z',\n",
       "  'version': '2020-02-26T23:30:04.866972',\n",
       "  'owner': 'someone@kubeflow.org',\n",
       "  'description': 'housing price prediction model using synthetic data',\n",
       "  'name': 'housing-price-model',\n",
       "  'model_type': 'linear_regression',\n",
       "  'uri': 'mockup-model.dat',\n",
       "  'training_framework': {'name': 'xgboost', 'version': '0.9.0'},\n",
       "  'hyperparameters': {'learning_rate': 0.1, 'n_estimators': 50},\n",
       "  'labels': None,\n",
       "  'kwargs': {}},\n",
       " {'id': 12,\n",
       "  'workspace': 'xgboost-synthetic',\n",
       "  'run': 'xgboost-synthetic-faring-run2020-02-26T23:44:47.344352',\n",
       "  'create_time': '2020-02-26T23:44:47.585805Z',\n",
       "  'version': '2020-02-26T23:44:47.585782',\n",
       "  'owner': 'someone@kubeflow.org',\n",
       "  'description': 'housing price prediction model using synthetic data',\n",
       "  'name': 'housing-price-model',\n",
       "  'model_type': 'linear_regression',\n",
       "  'uri': 'mockup-model.dat',\n",
       "  'training_framework': {'name': 'xgboost', 'version': '0.9.0'},\n",
       "  'hyperparameters': {'learning_rate': 0.1, 'n_estimators': 50},\n",
       "  'labels': None,\n",
       "  'kwargs': {}},\n",
       " {'id': 15,\n",
       "  'workspace': 'xgboost-synthetic',\n",
       "  'run': 'xgboost-synthetic-faring-run2020-02-26T23:48:06.287002',\n",
       "  'version': '2020-02-26T23:48:06.495138',\n",
       "  'owner': 'someone@kubeflow.org',\n",
       "  'description': 'housing price prediction model using synthetic data',\n",
       "  'name': 'housing-price-model',\n",
       "  'model_type': 'linear_regression',\n",
       "  'create_time': '2020-02-26T23:48:06.495166Z',\n",
       "  'uri': 'mockup-model.dat',\n",
       "  'training_framework': {'name': 'xgboost', 'version': '0.9.0'},\n",
       "  'hyperparameters': {'learning_rate': 0.1, 'n_estimators': 50},\n",
       "  'labels': None,\n",
       "  'kwargs': {}}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a workspace\n",
    "ws = create_workspace()\n",
    "ws.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "@dsl.pipeline(\n",
    "   name='Training pipeline',\n",
    "   description='A pipeline that trains an xgboost model for the Ames dataset.'\n",
    ")\n",
    "def train_pipeline(\n",
    "   ):      \n",
    "    command=[\"python\", preprocessor.executable.name, \"train\"]\n",
    "    train_op = dsl.ContainerOp(\n",
    "            name=\"train\", \n",
    "            image=builder.image_tag,        \n",
    "            command=command,\n",
    "            ).apply(\n",
    "                gcp.use_gcp_secret('user-gcp-sa'),\n",
    "            )\n",
    "    train_op.container.working_dir = \"/app\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "pipeline_func = train_pipeline\n",
    "pipeline_filename = pipeline_func.__name__ + '.pipeline.zip'\n",
    "compiler.Compiler().compile(pipeline_func, pipeline_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating experiment MockupModel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/8d173bc4-d2a7-4f88-9751-fc156bcf280b\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/105b69c8-dbf0-4ad4-8baa-e8eadfb38769\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# upload and execute\n",
    "EXPERIMENT_NAME = 'MockupModel'\n",
    "\n",
    "#Specify pipeline argument values\n",
    "arguments = {}\n",
    "\n",
    "# Get or create an experiment and submit a pipeline run\n",
    "client = kfp.Client()\n",
    "experiment = client.create_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "#Submit a pipeline run\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)\n",
    "\n",
    "#vvvvvvvvv This link leads to the run information page. (Note: There is a bug in JupyterLab that modifies the URL and makes the link stop working)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
